version: "3.8"

x-restart-policy: &default_restart_policy
  restart: ${DEFAULT_RESTART_POLICY:-unless-stopped}

services:
  mongo:
    build:
      context: ./mongo
    <<: *default_restart_policy
    env_file:
      - mongo/mongo.env
    hostname: "mongo"
    networks:
      - hubintranet
      - hubnet
    ports:
      - 127.0.0.1:27017:27017
    volumes:
      - mongo-data:/data/db

  keycloak:
    build:
      context: ./keycloak
      args:
        - KC_VER=20.0
    <<: *default_restart_policy
    command: start-dev --import-realm
    container_name: keycloak
    depends_on:
      keycloak-db:
        condition: service_healthy
    env_file:
      - keycloak/keycloak.env
    hostname: "keycloak"
    networks:
      - keycloaknet
      - hubintranet
      - hubnet
    ports:
      - 8080:8080
      - 8443:8443
    volumes:
      - ./keycloak/werkstatthub-realm.json:/opt/keycloak/data/import/wh.json:ro

  keycloak-config:
      image: quay.io/keycloak/keycloak:20.0
      depends_on:
        keycloak:
          condition: service_healthy
      entrypoint: ["sh","-c","chmod +x /init.sh && ./init.sh"]
      env_file:
        - keycloak/keycloak.env
      networks:
        - hubintranet
      user: root
      volumes:
        - ./keycloak/keycloak-config.sh:/init.sh

  keycloak-db:
    build:
      context: ./keycloak-db
    <<: *default_restart_policy
    container_name: keycloak-db
    env_file:
      - keycloak-db/postgres.env
    hostname: "keycloak-db"
    networks:
      - keycloaknet
    volumes:
      - keycloak-db-data:/var/lib/postgresql/data

  minio:
    build:
      context: ./minio
      args:
        - MINIO_VER=RELEASE.2023-05-27T05-56-19Z
    <<: *default_restart_policy
    command: server /data --console-address ":9090"
    depends_on:
      keycloak-config:
        condition: service_completed_successfully
    env_file:
      - minio/minio.env
    hostname: "minio"
    networks:
      - hubintranet
      - hubnet
    ports:
      - 9000:9000
      - 9090:9090
    volumes:
      - minio-data:/data

  minio-config:
      image: minio/mc
      depends_on:
        minio:
          condition: service_healthy
      entrypoint: ["sh","-c","chmod +x /minio-config.sh && ./minio-config.sh"]
      environment:
          - S3_ROOT_USER=${S3_ROOT_USER:?error}
          - S3_ROOT_PASSWORD=${S3_ROOT_PASSWORD:?error}
      networks:
        - hubintranet
      volumes:
        - ./minio/minio-config.sh:/minio-config.sh

  edc:
      build:
        context: ./edc
      <<: *default_restart_policy
      env_file:
        - edc/edc.env
      hostname: "edc"
      networks:
        - hubnet
      depends_on:
          edc-database:
              condition: service_healthy
      ports:
        - 8181:8181
        - 8182:8182
        - 8282:8282
        - 8183:8183
        - 8185:8185
        - 8186:8186
      volumes:
          - ./edc/resources:/resources

  edc-database:
      build:
          context: ./edc-db
      env_file:
          - edc-db/edc-db.env
      hostname: "edc-db"
      networks:
          - hubnet
      volumes:
          - edc-db-data:/var/lib/postgresql/data
          - ./edc-db/sql_tables:/docker-entrypoint-initdb.d/

  # just for demonstration purposes, not a production grade vault
  hashicorp-vault:
      build:
          context: hashicorp-vault
      hostname: "vault"
      ports:
          - 8200:8200
      env_file:
          - hashicorp-vault/hashicorp-vault.env
      cap_add:
          - IPC_LOCK
      networks:
          - hubnet

  api:
    build:
      context: ./api
    <<: *default_restart_policy
    # DEVELOPMENT: run with reload and mount api package code
    command: uvicorn --host 0.0.0.0 --reload api.main:app
    depends_on:
      mongo:
        condition: service_healthy
      minio-config:
        condition: service_completed_successfully
    env_file:
      - api/api.env
    hostname: "api"
    networks:
      - hubintranet
      - hubnet
    ports:
      - 8000:8000
    volumes:
      - ./api/api/:/home/api/api/

  docs:
    build:
      context: ./docs
    <<: *default_restart_policy
    ports:
      - 127.0.0.1:8001:80

  redis:  # broker for communication between api and diagnostics
    image: redis:alpine
    <<: *default_restart_policy
    expose:
      - 6379
    hostname: "redis"
    networks:
      - hubintranet
    command: redis-server --requirepass ${REDIS_PASSWORD:?error}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 2s
      retries: 5

  diagnostics:  # background service that integrates the dfki state machine
    build:
      context: ./diagnostics
    <<: *default_restart_policy
    command: celery -A diagnostics.tasks worker --loglevel=INFO
    env_file:
      - diagnostics/diagnostics.env
    hostname: "diagnostics"
    networks:
      - hubintranet
    volumes:
      - ./diagnostics/diagnostics:/home/runtime/diagnostics
      - ./diagnostics/models:/home/runtime/models

  knowledge-graph:  # utilized by the diagnostics service
    build: ./knowledge-graph
    <<: *default_restart_policy
    ports:
      - 3030:3030
    hostname: "knowledge-graph"
    networks:
      - hubintranet
      - hubnet

networks:
  hubnet:
  hubintranet:
    internal: true
  keycloaknet:
    internal: true

volumes:
  mongo-data:
  keycloak-db-data:
  minio-data:
  edc-db-data:
